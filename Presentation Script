ðŸŽ¤ Presentation Script (6 Minutes)

This script is structured strictly according to your teacher's 6-minute format and guiding principles. Speak clearly, slowly, and confidently!

1. Introduction: The Problem (30 seconds)

"Good morning, everyone. Our project, DS 5030, addresses a core problem in finance: How do we accurately model and predict the risk of an individual stock? Simple models, like those that assume a standard bell curve for price changes, consistently fail to capture the true risk. They fail because financial markets are inherently chaoticâ€”a behavior we call volatility clustering, where big moves follow big moves. Our goal was to apply non-parametric methods to model this financial time series behavior directly from the data, without making those restrictive assumptions."


2. Data: Amazon's Returns (1 minute)

"We sourced our data from a Kaggle collection of S&P 500 stocks, focusing on the financial domain.
"To ensure a clean, continuous analysis, we selected Amazon, ticker AMZN. This gave us a complete time series of daily closing prices from 2010 to late 2024, minimizing issues with missing data.
"Our core variable is the daily log return, which is the standardized daily percentage change. This simple plot of AMZN's daily returns reveals the first key phenomenon we are modeling: volatility clustering. As you can see, the periods of large spikesâ€”like the 2020 market shockâ€”tend to cluster together, showing that the risk is not constant, but changes over time. We calculated summary statistics, finding an average daily return of about $0.09\%$ but a standard deviation of $2\%$, highlighting the presence of high-magnitude movements."


3. Methods: Non-Parametric Tools (1 minute)

"To capture the true dynamics of these returns, we relied on two non-parametric techniques.
"The term non-parametric is central to our method: it means we did not assume a standard distribution shape, like the Normal distribution. Instead, we let the data tell us its own shape.
"First, we used Kernel Density Estimation, or KDE. This technique creates a smooth, continuous estimate of the return distribution's shape directly from all the observed data points.
"Second, we used Kernel Regression to smooth the line for AMZNâ€™s rolling volatility. This allowed us to clearly visualize and model the persistent volatility clustering effect over the 15-year period.
"Both of these non-parametric models are designed to capture the heavy tails and the time-varying risk that a simple model would miss."


4. Results: What We Learned (2 minutes)

"Our methods yielded two critical results.
"Result 1: The Heavy Tails.
"When we plotted the non-parametric KDE estimate against a standard Normal distributionâ€”the blue dashed lineâ€”the difference was clear. The KDE estimate (in red) has a sharper central peak and, most importantly, higher, fatter tails. This confirms the finance 'stylized fact' that extreme returnsâ€”both huge gains and huge lossesâ€”happen more frequently than a simple bell curve would ever predict. This is a crucial finding for risk management.
"Result 2: Risk Measures and Limitations.
"We then used the KDE model to generate a synthetic sequence of returns and applied a bootstrap method to estimate two key risk measures: the 95% Value-at-Risk (VaR) and the Expected Shortfall (ES).
* Our 95% VaR was estimated at approximately $-3.0\%$ daily loss.
* The comparison between the real and synthetic data was eye-opening: while the model was great at matching the mean and standard deviation, it significantly underestimated the kurtosisâ€”meaning it smoothed out the heavy tails and failed to fully replicate the most extreme losses.
"This tells us that the non-parametric KDE successfully captured the unconditional shape of the data, but it lost the temporal dependenceâ€”the crucial volatility clusteringâ€”which is key to modeling true, extreme market risk."


5. Conclusion and Future Work (30 seconds)

"In summary, non-parametric methods are highly effective at capturing the non-normal, heavy-tailed shape of financial returns. However, their primary limitation is the loss of temporal dependenceâ€”the crucial volatility clustering that drives risk.
"Our main finding is that for practical risk management, a hybrid approach is necessary. For future work, we propose combining a GARCH model, which is explicitly designed to capture volatility clustering, with non-parametric innovations to create a more robust framework that accounts for both the time-varying nature of risk and the heavy-tailed distribution of extreme events.
"Thank you, and I welcome any questions."

Would you like me to focus on creating slides or visuals for any of these sections?
